{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# L1 ImgIn shape = (?, 28,28,?)\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
    "# Conv -> (?,28,28,32)\n",
    "# Pool -> (?,14,14,32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1],\n",
    "                   strides=[1,2,2,1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 ImgIn szhape(?,14,14,32)\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
    "# Conv -> (?,14,14,64)\n",
    "# Pool -> (?,7,7,64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1],strides=[1,2,2,1], padding='SAME')\n",
    "l2 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.430877579\n",
      "Epoch: 0002 cost = 0.103119545\n",
      "Epoch: 0003 cost = 0.074848037\n",
      "Epoch: 0004 cost = 0.061116333\n",
      "Epoch: 0005 cost = 0.052689858\n",
      "Epoch: 0006 cost = 0.048708175\n",
      "Epoch: 0007 cost = 0.042461517\n",
      "Epoch: 0008 cost = 0.039646430\n",
      "Epoch: 0009 cost = 0.038041487\n",
      "Epoch: 0010 cost = 0.034246514\n",
      "Epoch: 0011 cost = 0.032940945\n",
      "Epoch: 0012 cost = 0.030250419\n",
      "Epoch: 0013 cost = 0.028825331\n",
      "Epoch: 0014 cost = 0.027123765\n",
      "Epoch: 0015 cost = 0.026325331\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "'''\n",
    "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "'''\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9938\n",
      "Label:  [5]\n",
      "Prediction:  [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "\n",
    "# if you have a OOM error, please refer to lab-11-X-mnist_deep_cnn_low_memory.py\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
